{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions in Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "print (tf.__version__) # 1.12.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the fashion MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "# returns 4 numpy arrays: 2 training sets and 2 test sets\n",
    "# images: 28x28 arrays, pixel values: 0 to 255\n",
    "# labels: array of integers: 0 to 9 => class of clothings\n",
    "# Training set: 60,000 images, Testing set: 10,000 images\n",
    "\n",
    "# class names are not included, need to create them to plot the images  \n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the values to a range of 0 to 1 of both data sets\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ReLu\n",
    "# Model a simple 3-layer neural network\n",
    "model_3 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model_3.summary() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model, specify: optimizer, loss function metrics\n",
    "model_3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model_3.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss, test_acc = model_3.evaluate(test_images, test_labels)\n",
    "print(\"Model - 3 layers - test loss:\", test_loss * 100)\n",
    "print(\"Model - 3 layers - test accuracy:\", test_acc * 100)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A simple 3-layer neural network\n",
    "# Activation function: sigmoid\n",
    "model_3_sigmoid = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model_3_sigmoid.summary() \n",
    "\n",
    "# Compile the model, specify: optimizer, loss function, metrics\n",
    "model_3_sigmoid.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 1.8507 - acc: 0.4552\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 1.0686 - acc: 0.6744\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.8124 - acc: 0.7265\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.7096 - acc: 0.7494\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.6561 - acc: 0.7626\n",
      "10000/10000 [==============================] - 1s 56us/step\n",
      "Model - 3 layers sigmoid - test loss: 65.07541139602662\n",
      "Model - 3 layers sigmoid - test accuracy: 76.19\n"
     ]
    }
   ],
   "source": [
    "model_3_sigmoid.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "test_loss, test_acc = model_3_sigmoid.evaluate(test_images, test_labels)\n",
    "print(\"Model - 3 layers sigmoid - test loss:\", test_loss * 100)\n",
    "print(\"Model - 3 layers sigmoid - test accuracy:\", test_acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A simple 3-layer neural network\n",
    "# Activation function: tanh\n",
    "model_3_tanh = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model_3_tanh.summary() \n",
    "\n",
    "# Compile the model, specify: optimizer, loss function metrics\n",
    "model_3_tanh.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_tanh.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "\n",
    "test_loss, test_acc = model_3_tanh.evaluate(test_images, test_labels)\n",
    "print(\"Model - 3 layers tanh - test loss:\", test_loss * 100)\n",
    "print(\"Model - 3 layers tanh - test accuracy:\", test_acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 1.4625 - acc: 0.5693 - val_loss: 0.9395 - val_acc: 0.7010\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.7812 - acc: 0.7385 - val_loss: 0.7015 - val_acc: 0.7534\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.6448 - acc: 0.7711 - val_loss: 0.6250 - val_acc: 0.7762\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.5854 - acc: 0.7922 - val_loss: 0.5816 - val_acc: 0.7903\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.5477 - acc: 0.8069 - val_loss: 0.5544 - val_acc: 0.8040\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.5215 - acc: 0.8177 - val_loss: 0.5350 - val_acc: 0.8089\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.5021 - acc: 0.8241 - val_loss: 0.5197 - val_acc: 0.8165\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.4875 - acc: 0.8292 - val_loss: 0.5093 - val_acc: 0.8201\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.4759 - acc: 0.8339 - val_loss: 0.5036 - val_acc: 0.8219\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.4667 - acc: 0.8378 - val_loss: 0.4923 - val_acc: 0.8256\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.4593 - acc: 0.8406 - val_loss: 0.4869 - val_acc: 0.8265\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.4526 - acc: 0.8430 - val_loss: 0.4847 - val_acc: 0.8265\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.4475 - acc: 0.8448 - val_loss: 0.4773 - val_acc: 0.8279\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.4424 - acc: 0.8467 - val_loss: 0.4738 - val_acc: 0.8312\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.4384 - acc: 0.8479 - val_loss: 0.4712 - val_acc: 0.8306\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.4349 - acc: 0.8481 - val_loss: 0.4688 - val_acc: 0.8314\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.4311 - acc: 0.8500 - val_loss: 0.4636 - val_acc: 0.8322\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.4281 - acc: 0.8515 - val_loss: 0.4671 - val_acc: 0.8295\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.4254 - acc: 0.8520 - val_loss: 0.4606 - val_acc: 0.8331\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.4229 - acc: 0.8532 - val_loss: 0.4592 - val_acc: 0.8366\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.5931 - acc: 0.5622 - val_loss: 1.0862 - val_acc: 0.6756\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.8986 - acc: 0.7155 - val_loss: 0.7827 - val_acc: 0.7339\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.7128 - acc: 0.7509 - val_loss: 0.6810 - val_acc: 0.7549\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.6392 - acc: 0.7703 - val_loss: 0.6299 - val_acc: 0.7714\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.5956 - acc: 0.7876 - val_loss: 0.5968 - val_acc: 0.7842\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.5638 - acc: 0.7989 - val_loss: 0.5701 - val_acc: 0.7941\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.5397 - acc: 0.8100 - val_loss: 0.5505 - val_acc: 0.8012\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.5208 - acc: 0.8171 - val_loss: 0.5386 - val_acc: 0.8049\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.5058 - acc: 0.8223 - val_loss: 0.5244 - val_acc: 0.8141\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.4928 - acc: 0.8278 - val_loss: 0.5165 - val_acc: 0.8148\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.4820 - acc: 0.8314 - val_loss: 0.5046 - val_acc: 0.8188\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.4724 - acc: 0.8339 - val_loss: 0.4973 - val_acc: 0.8211\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.4649 - acc: 0.8367 - val_loss: 0.4908 - val_acc: 0.8265\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.4582 - acc: 0.8389 - val_loss: 0.4886 - val_acc: 0.8219\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.4516 - acc: 0.8417 - val_loss: 0.4793 - val_acc: 0.8283\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.4459 - acc: 0.8436 - val_loss: 0.4747 - val_acc: 0.8305\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.4410 - acc: 0.8459 - val_loss: 0.4723 - val_acc: 0.8328\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.4360 - acc: 0.8472 - val_loss: 0.4685 - val_acc: 0.8328\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.4321 - acc: 0.8487 - val_loss: 0.4664 - val_acc: 0.8334\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.4276 - acc: 0.8505 - val_loss: 0.4603 - val_acc: 0.8347\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 2.2034 - acc: 0.3025 - val_loss: 2.0539 - val_acc: 0.4573\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.8194 - acc: 0.5303 - val_loss: 1.5850 - val_acc: 0.5195\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 1.4029 - acc: 0.6206 - val_loss: 1.2558 - val_acc: 0.6613\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 1.1483 - acc: 0.6734 - val_loss: 1.0626 - val_acc: 0.6816\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.9887 - acc: 0.7039 - val_loss: 0.9339 - val_acc: 0.7089\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.8807 - acc: 0.7214 - val_loss: 0.8504 - val_acc: 0.7215\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.8064 - acc: 0.7323 - val_loss: 0.7867 - val_acc: 0.7333\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.7548 - acc: 0.7408 - val_loss: 0.7448 - val_acc: 0.7411\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.7169 - acc: 0.7489 - val_loss: 0.7136 - val_acc: 0.7498\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.6880 - acc: 0.7547 - val_loss: 0.6885 - val_acc: 0.7552\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.6654 - acc: 0.7613 - val_loss: 0.6681 - val_acc: 0.7611\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.6463 - acc: 0.7655 - val_loss: 0.6534 - val_acc: 0.7635\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.6301 - acc: 0.7712 - val_loss: 0.6375 - val_acc: 0.7689\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.6160 - acc: 0.7769 - val_loss: 0.6272 - val_acc: 0.7720\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.6040 - acc: 0.7818 - val_loss: 0.6140 - val_acc: 0.7765\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.5922 - acc: 0.7868 - val_loss: 0.6027 - val_acc: 0.7800\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.5819 - acc: 0.7903 - val_loss: 0.5946 - val_acc: 0.7832\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.5724 - acc: 0.7939 - val_loss: 0.5909 - val_acc: 0.7873\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.5640 - acc: 0.7978 - val_loss: 0.5785 - val_acc: 0.7896\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.5557 - acc: 0.8010 - val_loss: 0.5720 - val_acc: 0.7954\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 1.4640 - acc: 0.5839 - val_loss: 0.9360 - val_acc: 0.6981\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.7753 - acc: 0.7407 - val_loss: 0.6971 - val_acc: 0.7489\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.6418 - acc: 0.7713 - val_loss: 0.6235 - val_acc: 0.7735\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.5835 - acc: 0.7917 - val_loss: 0.5819 - val_acc: 0.7865\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.5463 - acc: 0.8078 - val_loss: 0.5540 - val_acc: 0.8025\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.5206 - acc: 0.8158 - val_loss: 0.5348 - val_acc: 0.8093\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.5015 - acc: 0.8243 - val_loss: 0.5189 - val_acc: 0.8143\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.4874 - acc: 0.8297 - val_loss: 0.5081 - val_acc: 0.8205\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.4758 - acc: 0.8329 - val_loss: 0.4998 - val_acc: 0.8228\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.4662 - acc: 0.8372 - val_loss: 0.4909 - val_acc: 0.8244\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.4587 - acc: 0.8398 - val_loss: 0.4858 - val_acc: 0.8253\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.4523 - acc: 0.8427 - val_loss: 0.4811 - val_acc: 0.8276\n",
      "Epoch 13/20\n",
      "37376/60000 [=================>............] - ETA: 0s - loss: 0.4510 - acc: 0.8412"
     ]
    }
   ],
   "source": [
    "# Combine the networks using all activations\n",
    "epochs = 25\n",
    "\n",
    "for activation in [None, 'relu', 'sigmoid', 'tanh']:\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "    model.add(keras.layers.Dense(128,activation=activation))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    history=model.fit(train_images, train_labels,\n",
    "                     batch_size=128,\n",
    "                     epochs=20,\n",
    "                     verbose=1,\n",
    "                     validation_data=(test_images, test_labels))\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    \n",
    "plt.title('Comparing the loss of all activations')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['None', 'relu', 'sigmoid', 'tanh'], loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
